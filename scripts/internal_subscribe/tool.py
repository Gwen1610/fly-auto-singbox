import base64
import random
import re
import string
import urllib.parse

REGION_PATTERNS = {
    "America": re.compile(
        r"(ðŸ‡ºðŸ‡¸|ðŸ‡ºðŸ‡²|ç¾Žå›½|ç¾Žåœ‹|ç¾Žè¥¿|ç¾Žä¸œ|ç¾Žæ±|æ´›æ‰çŸ¶|æ´›æ‰ç£¯|çº½çº¦|ç´ç´„|æ—§é‡‘å±±|èˆŠé‡‘å±±|United\\s*States|\\bUSA?\\b|America|US\\d+)",
        re.IGNORECASE,
    ),
    "HongKong": re.compile(r"(ðŸ‡­ðŸ‡°|é¦™æ¸¯|æ¸¯çº¿|æ¸¯ç·š|Hong\\s*Kong|HongKong|\\bHK\\b|HK\\d+|HKG)", re.IGNORECASE),
    "Singapore": re.compile(r"(ðŸ‡¸ðŸ‡¬|æ–°åŠ å¡|ç‹®åŸŽ|ç…åŸŽ|Singapore|\\bSG\\b|SG\\d+|SGP)", re.IGNORECASE),
    "Japan": re.compile(r"(ðŸ‡¯ðŸ‡µ|æ—¥æœ¬|ä¸œäº¬|æ±äº¬|å¤§é˜ª|Japan|\\bJP\\b|JP\\d+|JPN)", re.IGNORECASE),
}

REGION_EMOJI = {
    "America": "ðŸ‡ºðŸ‡¸",
    "HongKong": "ðŸ‡­ðŸ‡°",
    "Singapore": "ðŸ‡¸ðŸ‡¬",
    "Japan": "ðŸ‡¯ðŸ‡µ",
}


def b64Decode(value: str) -> bytes:
    raw = urllib.parse.unquote(value.strip())
    padding = (-len(raw)) % 4
    raw = raw + ("=" * padding)
    return base64.urlsafe_b64decode(raw.encode("utf-8"))


def noblankLine(data: str) -> str:
    return "\n".join(line.strip() for line in data.splitlines() if line.strip())


def genName(length: int = 8) -> str:
    chars = string.ascii_letters + string.digits
    return "".join(random.choice(chars) for _ in range(length))


def get_protocol(uri: str):
    try:
        match = re.search(r"^(.+?)://", uri)
    except Exception:
        return None
    if not match:
        return None
    proto = match.group(1)
    if proto == "hy2":
        proto = "hysteria2"
    elif proto == "wireguard":
        proto = "wg"
    elif proto == "http2":
        proto = "http"
    elif proto == "socks5":
        proto = "socks"
    return proto


def rename(name: str) -> str:
    if not isinstance(name, str):
        return name
    stripped = name.strip()
    for region, pattern in REGION_PATTERNS.items():
        if pattern.search(stripped):
            emoji = REGION_EMOJI[region]
            if stripped.startswith(emoji):
                return stripped
            return f"{emoji} {stripped}"
    return stripped


def proDuplicateNodeName(grouped_nodes):
    # grouped_nodes: dict[tag_group, list[node]]
    seen = {}
    for _, nodes in grouped_nodes.items():
        for node in nodes:
            name = str(node.get("tag", "")).strip()
            if not name:
                continue
            count = seen.get(name, 0)
            if count == 0:
                seen[name] = 1
                continue
            new_name = f"{name}-{count + 1}"
            while new_name in seen:
                count += 1
                new_name = f"{name}-{count + 1}"
            node["tag"] = new_name
            seen[name] = count + 1
            seen[new_name] = 1
