#!/usr/bin/env bash
set -euo pipefail

FLY_VERSION="0.1.0"
ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
CONFIG_DIR="${ROOT_DIR}/config"
BUILD_DIR="${ROOT_DIR}/build"
STATE_DIR="${ROOT_DIR}/state"
ENV_FILE="${CONFIG_DIR}/fly.env"
GROUPS_FILE="${CONFIG_DIR}/groups.json"
ROUTES_FILE="${CONFIG_DIR}/routes.json"

log() {
  printf '[fly] %s\n' "$*"
}

warn() {
  printf '[fly][warn] %s\n' "$*" >&2
}

die() {
  printf '[fly][error] %s\n' "$*" >&2
  exit 1
}

need_cmd() {
  command -v "$1" >/dev/null 2>&1 || die "missing required command: $1"
}

is_true() {
  case "${1:-}" in
    1|true|TRUE|yes|YES|on|ON) return 0 ;;
    *) return 1 ;;
  esac
}

usage() {
  cat <<'EOF'
fly - one-command sing-box bootstrap toolkit

Usage:
  ./fly init [--force]
  ./fly apply [--dry-run]
  ./fly status
  ./fly logs [-f] [-n lines]
  ./fly rollback
  ./fly help

Command summary:
  init       Create config templates under ./config (--force to overwrite)
  apply      Build config from subscription + groups + routes, then deploy
  status     Show current sing-box and service status
  logs       Show service logs (journalctl)
  rollback   Restore previous config snapshot and restart service
  help       Show this help
EOF
}

backup_existing_file() {
  local target_file="$1"
  [[ -f "${target_file}" ]] || return 0
  mkdir -p "${STATE_DIR}"
  local base_name
  base_name="$(basename "${target_file}")"
  local backup_file="${STATE_DIR}/${base_name}.bak.$(date +%Y%m%d%H%M%S)"
  cp "${target_file}" "${backup_file}"
  log "backup ${target_file} -> ${backup_file}"
}

init_files() {
  local force="false"
  while [[ $# -gt 0 ]]; do
    case "$1" in
      --force|-f) force="true" ;;
      *) die "unknown flag for init: $1" ;;
    esac
    shift
  done

  mkdir -p "${CONFIG_DIR}" "${BUILD_DIR}" "${STATE_DIR}"

  if [[ ! -f "${ENV_FILE}" ]] || is_true "${force}"; then
    if [[ -f "${ENV_FILE}" ]] && is_true "${force}"; then
      backup_existing_file "${ENV_FILE}"
    fi
    cat > "${ENV_FILE}" <<'EOF'
# Required: set one of SUBSCRIPTION_URL or SUBSCRIPTION_FILE.
SUBSCRIPTION_URL=""
SUBSCRIPTION_FILE=""

# Supported values:
# - auto (recommended): auto-detect source format.
# - singbox: SUBSCRIPTION_URL directly returns sing-box JSON with "outbounds".
# - clash/v2ray: convert via SUBCONVERTER_URL.
SUBSCRIPTION_FORMAT="auto"
SUBCONVERTER_URL="http://127.0.0.1:25500/sub"
# Optional image override for auto-start local subconverter.
SUBCONVERTER_IMAGE="docker.1ms.run/tindy2013/subconverter:latest"

# Install and runtime
SINGBOX_VERSION="1.12.20"
INSTALL_DIR="/usr/local/bin"
CONFIG_PATH="/etc/sing-box/config.json"
SERVICE_NAME="sing-box"

# Generated config defaults
INBOUND_LISTEN="127.0.0.1"
INBOUND_MIXED_PORT="7890"
LOG_LEVEL="info"
FINAL_OUTBOUND="proxy"
CHECK_URL="https://www.gstatic.com/generate_204"
# Compatibility toggle for sing-box 1.12 special outbounds validation.
ENABLE_DEPRECATED_SPECIAL_OUTBOUNDS="true"
EOF
    if is_true "${force}" && [[ -f "${ENV_FILE}" ]]; then
      log "overwritten ${ENV_FILE}"
    else
      log "created ${ENV_FILE}"
    fi
  else
    log "exists ${ENV_FILE}, skip"
  fi

  if [[ ! -f "${GROUPS_FILE}" ]] || is_true "${force}"; then
    if [[ -f "${GROUPS_FILE}" ]] && is_true "${force}"; then
      backup_existing_file "${GROUPS_FILE}"
    fi
    cat > "${GROUPS_FILE}" <<'EOF'
[
  {
    "tag": "all-proxies",
    "type": "selector",
    "include_regex": ".*"
  },
  {
    "tag": "hk-auto",
    "type": "urltest",
    "include_regex": "((^|[^a-z])(hk|hong kong|hongkong)($|[^a-z])|香港|港线|港線)",
    "allow_empty": true,
    "url": "https://www.gstatic.com/generate_204",
    "interval": "5m",
    "tolerance": 50
  },
  {
    "tag": "hk-proxy",
    "type": "selector",
    "members": ["hk-auto", "all-proxies", "direct"]
  },
  {
    "tag": "us-auto",
    "type": "urltest",
    "include_regex": "((^|[^a-z])(us|usa|united states|america|la|los angeles|sjc|sfo|sea|ny|new york)($|[^a-z])|美国|美國|美西|美东|美東|洛杉矶|洛杉磯|纽约|紐約|西雅图|西雅圖|圣何塞|聖何塞|旧金山|舊金山)",
    "allow_empty": true,
    "url": "https://www.gstatic.com/generate_204",
    "interval": "5m",
    "tolerance": 50
  },
  {
    "tag": "us-proxy",
    "type": "selector",
    "members": ["us-auto", "all-proxies", "direct"]
  },
  {
    "tag": "jp-auto",
    "type": "urltest",
    "include_regex": "((^|[^a-z])(jp|japan|tokyo|osaka)($|[^a-z])|日本|东京|東京|大阪|日線|日线)",
    "allow_empty": true,
    "url": "https://www.gstatic.com/generate_204",
    "interval": "5m",
    "tolerance": 50
  },
  {
    "tag": "jp-proxy",
    "type": "selector",
    "members": ["jp-auto", "all-proxies", "direct"]
  },
  {
    "tag": "kr-auto",
    "type": "urltest",
    "include_regex": "((^|[^a-z])(kr|korea|south korea|seoul)($|[^a-z])|韩国|韓國|首尔|首爾|韩线|韓線)",
    "allow_empty": true,
    "url": "https://www.gstatic.com/generate_204",
    "interval": "5m",
    "tolerance": 50
  },
  {
    "tag": "kr-proxy",
    "type": "selector",
    "members": ["kr-auto", "all-proxies", "direct"]
  },
  {
    "tag": "sg-auto",
    "type": "urltest",
    "include_regex": "((^|[^a-z])(sg|singapore)($|[^a-z])|新加坡|獅城|狮城|新線|新线)",
    "allow_empty": true,
    "url": "https://www.gstatic.com/generate_204",
    "interval": "5m",
    "tolerance": 50
  },
  {
    "tag": "sg-proxy",
    "type": "selector",
    "members": ["sg-auto", "all-proxies", "direct"]
  },
  {
    "tag": "proxy",
    "type": "selector",
    "members": ["us-proxy", "hk-proxy", "jp-proxy", "kr-proxy", "sg-proxy", "all-proxies", "direct"]
  }
]
EOF
    if is_true "${force}" && [[ -f "${GROUPS_FILE}" ]]; then
      log "overwritten ${GROUPS_FILE}"
    else
      log "created ${GROUPS_FILE}"
    fi
  else
    log "exists ${GROUPS_FILE}, skip"
  fi

  if [[ ! -f "${ROUTES_FILE}" ]] || is_true "${force}"; then
    if [[ -f "${ROUTES_FILE}" ]] && is_true "${force}"; then
      backup_existing_file "${ROUTES_FILE}"
    fi
    cat > "${ROUTES_FILE}" <<'EOF'
{
  "final": "proxy",
  "rules": [
    {
      "domain_suffix": [
        "openai.com",
        "chatgpt.com",
        "oaistatic.com",
        "claude.ai",
        "anthropic.com",
        "gemini.google.com",
        "aistudio.google.com",
        "ai.google.dev",
        "generativelanguage.googleapis.com",
        "perplexity.ai",
        "perplexity.com",
        "x.ai",
        "grok.com",
        "cursor.com",
        "cursor.sh",
        "githubcopilot.com",
        "copilot.microsoft.com"
      ],
      "outbound": "us-proxy"
    },
    {
      "domain_suffix": [
        "google.com",
        "googleapis.com",
        "gstatic.com",
        "ggpht.com",
        "youtube.com",
        "googlevideo.com",
        "ytimg.com"
      ],
      "outbound": "hk-proxy"
    },
    {
      "geoip": ["cn"],
      "outbound": "direct"
    }
  ]
}
EOF
    if is_true "${force}" && [[ -f "${ROUTES_FILE}" ]]; then
      log "overwritten ${ROUTES_FILE}"
    else
      log "created ${ROUTES_FILE}"
    fi
  else
    log "exists ${ROUTES_FILE}, skip"
  fi

  log "init complete. Edit ${ENV_FILE}, ${GROUPS_FILE}, ${ROUTES_FILE}, then run: ./fly apply"
}

load_env() {
  [[ -f "${ENV_FILE}" ]] || die "missing ${ENV_FILE}, run ./fly init first"
  # shellcheck disable=SC1090
  source "${ENV_FILE}"
  : "${SUBSCRIPTION_URL:=}"
  : "${SUBSCRIPTION_FILE:=}"
  : "${SUBSCRIPTION_FORMAT:=auto}"
  : "${SUBCONVERTER_URL:=http://127.0.0.1:25500/sub}"
  : "${SUBCONVERTER_IMAGE:=docker.1ms.run/tindy2013/subconverter:latest}"
  : "${SINGBOX_VERSION:=1.12.20}"
  : "${INSTALL_DIR:=/usr/local/bin}"
  : "${CONFIG_PATH:=/etc/sing-box/config.json}"
  : "${SERVICE_NAME:=sing-box}"
  : "${INBOUND_LISTEN:=127.0.0.1}"
  : "${INBOUND_MIXED_PORT:=7890}"
  : "${LOG_LEVEL:=info}"
  : "${FINAL_OUTBOUND:=proxy}"
  : "${CHECK_URL:=https://www.gstatic.com/generate_204}"
  : "${ENABLE_DEPRECATED_SPECIAL_OUTBOUNDS:=true}"
}

abs_path() {
  local path="$1"
  if [[ "${path}" = /* ]]; then
    printf '%s\n' "${path}"
  else
    printf '%s\n' "${ROOT_DIR}/${path}"
  fi
}

url_encode() {
  local value="$1"
  python3 - "$value" <<'PY'
import sys
from urllib.parse import quote
print(quote(sys.argv[1], safe=""))
PY
}

validate_subscription_json() {
  local input_file="$1"
  python3 - "${input_file}" <<'PY'
import json
import sys
from pathlib import Path

path = Path(sys.argv[1])
try:
    data = json.loads(path.read_text(encoding="utf-8"))
except Exception as exc:
    raise SystemExit(f"invalid subscription JSON: {exc}") from exc

outbounds = data.get("outbounds")
if not isinstance(outbounds, list) or not outbounds:
    raise SystemExit("subscription JSON must contain non-empty outbounds[]")

for item in outbounds:
    tag = item.get("tag") if isinstance(item, dict) else None
    if not isinstance(tag, str) or not tag.strip():
        raise SystemExit("every outbound in subscription must contain string tag")
PY
}

detect_subscription_content_kind() {
  local input_file="$1"
  python3 - "${input_file}" <<'PY'
import base64
import json
import re
import sys
from pathlib import Path

text = Path(sys.argv[1]).read_text(encoding="utf-8", errors="ignore").strip()
if not text:
    print("empty")
    raise SystemExit(0)

try:
    data = json.loads(text)
    if isinstance(data, dict) and isinstance(data.get("outbounds"), list):
        print("singbox_json")
        raise SystemExit(0)
except Exception:
    pass

lower_text = text.lower()
if "<html" in lower_text[:300]:
    print("html")
    raise SystemExit(0)

if "proxies:" in lower_text or "proxy-providers:" in lower_text:
    print("clash")
    raise SystemExit(0)

uri_pat = re.compile(r"(ss|vmess|vless|trojan|hysteria2?|tuic)://", re.IGNORECASE)
if uri_pat.search(text):
    print("uri")
    raise SystemExit(0)

compact = "".join(text.split())
if compact and re.fullmatch(r"[A-Za-z0-9+/=]+", compact):
    try:
        decoded = base64.b64decode(compact, validate=True).decode("utf-8", errors="ignore")
        if uri_pat.search(decoded):
            print("uri_b64")
            raise SystemExit(0)
        print("unknown_b64")
        raise SystemExit(0)
    except Exception:
        pass

print("unknown")
PY
}

normalize_subconverter_url() {
  if [[ -z "${SUBCONVERTER_URL}" ]]; then
    SUBCONVERTER_URL="http://127.0.0.1:25500/sub"
  fi
  if [[ "${SUBCONVERTER_URL}" != */sub ]]; then
    SUBCONVERTER_URL="${SUBCONVERTER_URL%/}/sub"
  fi
}

subconverter_base_url() {
  normalize_subconverter_url
  printf '%s\n' "${SUBCONVERTER_URL%/sub}"
}

url_reachable() {
  local url="$1"
  curl -sS -o /dev/null --max-time 4 "${url}"
}

is_local_subconverter_target() {
  local base_url
  base_url="$(subconverter_base_url)"
  [[ "${base_url}" =~ ^https?://(127\.0\.0\.1|localhost)(:[0-9]+)?$ ]]
}

ensure_docker_for_subconverter() {
  if command -v docker >/dev/null 2>&1; then
    return 0
  fi

  require_root
  if command -v apt-get >/dev/null 2>&1; then
    log "docker not found; installing docker.io via apt"
    apt-get update -y
    apt-get install -y docker.io
  elif command -v dnf >/dev/null 2>&1; then
    log "docker not found; installing docker via dnf"
    dnf install -y docker
  elif command -v yum >/dev/null 2>&1; then
    log "docker not found; installing docker via yum"
    yum install -y docker
  else
    die "docker is required to auto-start local subconverter, but no supported package manager found"
  fi
}

start_local_subconverter_container() {
  ensure_docker_for_subconverter

  if command -v systemctl >/dev/null 2>&1; then
    systemctl enable --now docker >/dev/null 2>&1 || true
  fi

  if docker ps --format '{{.Names}}' | grep -qx 'subconverter'; then
    return 0
  fi

  if docker ps -a --format '{{.Names}}' | grep -qx 'subconverter'; then
    docker start subconverter >/dev/null
    return 0
  fi

  local images=(
    "${SUBCONVERTER_IMAGE}"
    "docker.1ms.run/tindy2013/subconverter:latest"
    "tindy2013/subconverter:latest"
  )
  local image
  for image in "${images[@]}"; do
    [[ -n "${image}" ]] || continue
    if docker run -d \
      --name subconverter \
      --restart unless-stopped \
      -p 25500:25500 \
      "${image}" >/dev/null 2>&1; then
      log "started local subconverter container using image ${image}"
      return 0
    fi
  done

  die "failed to start local subconverter container; set SUBCONVERTER_URL to a reachable converter endpoint"
}

ensure_subconverter_ready() {
  local base_url
  base_url="$(subconverter_base_url)"
  if url_reachable "${base_url}"; then
    return 0
  fi

  if ! is_local_subconverter_target; then
    die "SUBCONVERTER_URL is unreachable: ${SUBCONVERTER_URL}"
  fi

  log "local subconverter not reachable; attempting auto-start"
  start_local_subconverter_container

  local attempt
  for attempt in $(seq 1 20); do
    if url_reachable "${base_url}"; then
      log "local subconverter is ready at ${SUBCONVERTER_URL}"
      return 0
    fi
    sleep 1
  done

  die "local subconverter did not become ready at ${base_url}"
}

convert_subscription_via_subconverter() {
  local source_url="$1"
  local output_file="$2"
  ensure_subconverter_ready
  local encoded_url
  encoded_url="$(url_encode "${source_url}")"
  curl -fsSL "${SUBCONVERTER_URL}?target=singbox&url=${encoded_url}" -o "${output_file}"
  validate_subscription_json "${output_file}"
}

fetch_subscription_json() {
  local output_file="$1"
  mkdir -p "$(dirname "${output_file}")"

  if [[ -n "${SUBSCRIPTION_FILE}" ]]; then
    local src
    src="$(abs_path "${SUBSCRIPTION_FILE}")"
    [[ -f "${src}" ]] || die "SUBSCRIPTION_FILE does not exist: ${src}"
    cp "${src}" "${output_file}"
    if [[ "${SUBSCRIPTION_FORMAT}" == "auto" ]]; then
      local local_kind
      local_kind="$(detect_subscription_content_kind "${output_file}")"
      [[ "${local_kind}" == "singbox_json" ]] || die "SUBSCRIPTION_FILE with SUBSCRIPTION_FORMAT=auto must be sing-box JSON (detected: ${local_kind})"
    elif [[ "${SUBSCRIPTION_FORMAT}" != "singbox" ]]; then
      die "SUBSCRIPTION_FILE currently supports only singbox JSON input (set SUBSCRIPTION_FORMAT=auto or singbox)"
    fi
    validate_subscription_json "${output_file}"
    return
  fi

  [[ -n "${SUBSCRIPTION_URL}" ]] || die "set SUBSCRIPTION_URL or SUBSCRIPTION_FILE in ${ENV_FILE}"
  need_cmd curl

  if [[ "${SUBSCRIPTION_FORMAT}" == "auto" ]]; then
    local raw_file
    raw_file="$(mktemp)"
    curl -fsSL "${SUBSCRIPTION_URL}" -o "${raw_file}"

    local detected_kind
    detected_kind="$(detect_subscription_content_kind "${raw_file}")"
    case "${detected_kind}" in
      singbox_json)
        mv "${raw_file}" "${output_file}"
        validate_subscription_json "${output_file}"
        return
        ;;
      clash|uri|uri_b64|unknown_b64|unknown)
        log "auto-detected subscription kind: ${detected_kind}; converting with subconverter"
        rm -f "${raw_file}"
        convert_subscription_via_subconverter "${SUBSCRIPTION_URL}" "${output_file}"
        return
        ;;
      html)
        rm -f "${raw_file}"
        die "subscription URL returned HTML (likely auth/URL issue), cannot parse"
        ;;
      empty)
        rm -f "${raw_file}"
        die "subscription URL returned empty content"
        ;;
      *)
        rm -f "${raw_file}"
        die "unsupported auto-detected subscription content: ${detected_kind}"
        ;;
    esac
  fi

  case "${SUBSCRIPTION_FORMAT}" in
    singbox)
      curl -fsSL "${SUBSCRIPTION_URL}" -o "${output_file}"
      ;;
    clash|v2ray)
      convert_subscription_via_subconverter "${SUBSCRIPTION_URL}" "${output_file}"
      ;;
    *)
      die "unsupported SUBSCRIPTION_FORMAT=${SUBSCRIPTION_FORMAT} (supported: auto, singbox, clash, v2ray)"
      ;;
  esac

  validate_subscription_json "${output_file}"
}

render_config() {
  local subscription_file="$1"
  local output_file="$2"
  python3 - "${subscription_file}" "${GROUPS_FILE}" "${ROUTES_FILE}" "${output_file}" \
    "${INBOUND_LISTEN}" "${INBOUND_MIXED_PORT}" "${FINAL_OUTBOUND}" "${LOG_LEVEL}" <<'PY'
import json
import re
import sys
from pathlib import Path

subscription_path = Path(sys.argv[1])
groups_path = Path(sys.argv[2])
routes_path = Path(sys.argv[3])
output_path = Path(sys.argv[4])
inbound_listen = sys.argv[5]
inbound_port = int(sys.argv[6])
final_outbound_default = sys.argv[7]
log_level = sys.argv[8]

subscription = json.loads(subscription_path.read_text(encoding="utf-8"))
groups_cfg = json.loads(groups_path.read_text(encoding="utf-8"))
routes_cfg = json.loads(routes_path.read_text(encoding="utf-8"))

if not isinstance(groups_cfg, list):
    raise SystemExit("groups.json must be an array")
if not isinstance(routes_cfg, dict):
    raise SystemExit("routes.json must be an object")

subscription_outbounds = subscription.get("outbounds")
if not isinstance(subscription_outbounds, list):
    raise SystemExit("subscription must contain outbounds array")

node_tags = []
for item in subscription_outbounds:
    if not isinstance(item, dict):
        raise SystemExit("subscription outbounds must be objects")
    tag = item.get("tag")
    if not isinstance(tag, str) or not tag:
        raise SystemExit("every subscription outbound must have a non-empty tag")
    node_tags.append(tag)

def dedupe(items):
    seen = set()
    ordered = []
    for value in items:
        if value not in seen:
            ordered.append(value)
            seen.add(value)
    return ordered

group_tags = []
rendered_groups = []
for group in groups_cfg:
    if not isinstance(group, dict):
        raise SystemExit("each group item must be an object")
    tag = group.get("tag")
    group_type = group.get("type")
    if not isinstance(tag, str) or not tag:
        raise SystemExit("group tag is required")
    if group_type not in {"selector", "urltest"}:
        raise SystemExit(f"group {tag}: type must be selector or urltest")

    members = group.get("members")
    if members is None:
        include_regex = group.get("include_regex", ".*")
        exclude_regex = group.get("exclude_regex")
        try:
            include_pat = re.compile(include_regex, re.IGNORECASE)
            exclude_pat = re.compile(exclude_regex, re.IGNORECASE) if exclude_regex else None
        except re.error as exc:
            raise SystemExit(f"group {tag}: invalid regex: {exc}") from exc
        members = []
        for node_tag in node_tags:
            if not include_pat.search(node_tag):
                continue
            if exclude_pat and exclude_pat.search(node_tag):
                continue
            members.append(node_tag)
    if not isinstance(members, list):
        raise SystemExit(f"group {tag}: members must be array")
    members = [str(v) for v in members if str(v).strip()]
    members = dedupe(members)

    allow_empty = bool(group.get("allow_empty", False))
    if not members and not allow_empty:
        raise SystemExit(f"group {tag}: no members matched; set allow_empty=true to bypass")

    rendered = {
        "type": group_type,
        "tag": tag,
        "outbounds": members,
    }
    if group_type == "urltest":
        rendered["url"] = group.get("url", "https://www.gstatic.com/generate_204")
        rendered["interval"] = group.get("interval", "5m")
        rendered["tolerance"] = int(group.get("tolerance", 50))
    rendered_groups.append(rendered)
    group_tags.append(tag)

fixed_outbounds = [
    {"type": "direct", "tag": "direct"},
    {"type": "block", "tag": "block"},
]

all_tags = dedupe(node_tags + group_tags + [item["tag"] for item in fixed_outbounds])
for group in rendered_groups:
    for member in group["outbounds"]:
        if member not in all_tags:
            raise SystemExit(f"group {group['tag']}: unknown outbound member tag: {member}")

route_rules = routes_cfg.get("rules", [])
if not isinstance(route_rules, list):
    raise SystemExit("routes.json rules must be an array")
route_final = routes_cfg.get("final", final_outbound_default)
if route_final not in all_tags:
    raise SystemExit(f"route final outbound does not exist: {route_final}")

tags_all_outbounds = [item["tag"] for item in subscription_outbounds + rendered_groups + fixed_outbounds]
dup_tags = [tag for tag in sorted(set(tags_all_outbounds)) if tags_all_outbounds.count(tag) > 1]
if dup_tags:
    raise SystemExit(f"duplicate outbound tags detected: {', '.join(dup_tags)}")

config = {
    "log": {"level": log_level},
    "dns": {
        "servers": [
            {"tag": "dns-direct", "address": "223.5.5.5", "detour": "direct"},
            {"tag": "dns-remote", "address": "https://1.1.1.1/dns-query", "detour": route_final},
        ]
    },
    "inbounds": [
        {
            "type": "mixed",
            "tag": "mixed-in",
            "listen": inbound_listen,
            "listen_port": inbound_port,
            "sniff": True,
        }
    ],
    "outbounds": subscription_outbounds + rendered_groups + fixed_outbounds,
    "route": {
        "auto_detect_interface": True,
        "final": route_final,
        "rules": route_rules,
    },
}

output_path.parent.mkdir(parents=True, exist_ok=True)
output_path.write_text(json.dumps(config, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")
PY
}

check_with_local_sing_box() {
  local config_file="$1"
  if command -v sing-box >/dev/null 2>&1; then
    log "running local validation: sing-box check -c ${config_file}"
    if is_true "${ENABLE_DEPRECATED_SPECIAL_OUTBOUNDS}"; then
      ENABLE_DEPRECATED_SPECIAL_OUTBOUNDS=true sing-box check -c "${config_file}" >/dev/null
    else
      sing-box check -c "${config_file}" >/dev/null
    fi
  else
    warn "sing-box not found locally; skipped local check (this is fine for first bootstrap)"
  fi
}

require_root() {
  if [[ "${EUID}" -ne 0 ]]; then
    die "this command requires root. rerun with sudo."
  fi
}

detect_arch() {
  local machine
  machine="$(uname -m)"
  case "${machine}" in
    x86_64|amd64) printf 'amd64\n' ;;
    aarch64|arm64) printf 'arm64\n' ;;
    *)
      die "unsupported architecture: ${machine}"
      ;;
  esac
}

resolve_release_asset() {
  local desired_version="$1"
  local arch="$2"
  local releases_file="$3"
  python3 - "${desired_version}" "${arch}" "${releases_file}" <<'PY'
import json
import sys
from pathlib import Path

desired = sys.argv[1]
arch = sys.argv[2]
releases = json.loads(Path(sys.argv[3]).read_text(encoding="utf-8"))

if not isinstance(releases, list):
    raise SystemExit("unexpected releases API response")

target = None
if desired == "latest":
    for rel in releases:
        if not rel.get("prerelease"):
            target = rel
            break
else:
    desired_norm = desired.lstrip("v")
    for rel in releases:
        tag = str(rel.get("tag_name", "")).lstrip("v")
        if tag == desired_norm:
            target = rel
            break

if target is None:
    raise SystemExit(f"cannot find release for version: {desired}")

asset_url = ""
for asset in target.get("assets", []):
    name = str(asset.get("name", ""))
    url = str(asset.get("browser_download_url", ""))
    if f"linux-{arch}" in name and name.endswith(".tar.gz"):
        asset_url = url
        break

if not asset_url:
    raise SystemExit(f"no linux-{arch} .tar.gz asset found for release {target.get('tag_name')}")

print(str(target.get("tag_name", "")))
print(asset_url)
PY
}

install_sing_box_if_needed() {
  need_cmd curl
  need_cmd tar
  need_cmd install
  need_cmd python3

  local current_version=""
  if command -v sing-box >/dev/null 2>&1; then
    current_version="$(sing-box version 2>/dev/null | head -n 1 || true)"
    if [[ "${SINGBOX_VERSION}" != "latest" ]] && [[ "${current_version}" == *"${SINGBOX_VERSION}"* ]]; then
      log "sing-box already installed and matches version ${SINGBOX_VERSION}"
      return
    fi
  fi

  local arch
  arch="$(detect_arch)"
  local tmp_dir
  tmp_dir="$(mktemp -d)"
  trap 'rm -rf "${tmp_dir:-}"' RETURN

  local releases_file
  releases_file="${tmp_dir}/releases.json"
  curl -fsSL "https://api.github.com/repos/SagerNet/sing-box/releases" -o "${releases_file}"

  local release_meta
  release_meta="$(resolve_release_asset "${SINGBOX_VERSION}" "${arch}" "${releases_file}")"
  local release_tag asset_url
  release_tag="$(printf '%s\n' "${release_meta}" | sed -n '1p')"
  asset_url="$(printf '%s\n' "${release_meta}" | sed -n '2p')"
  [[ -n "${asset_url}" ]] || die "failed to resolve sing-box release asset"

  local tarball
  tarball="${tmp_dir}/sing-box.tar.gz"
  log "downloading sing-box ${release_tag} (${arch})"
  curl -fsSL "${asset_url}" -o "${tarball}"

  tar -xzf "${tarball}" -C "${tmp_dir}"
  local binary_path
  binary_path="$(find "${tmp_dir}" -type f -name sing-box | head -n 1 || true)"
  [[ -n "${binary_path}" ]] || die "cannot find sing-box binary in downloaded archive"

  install -d "${INSTALL_DIR}"
  install -m 755 "${binary_path}" "${INSTALL_DIR}/sing-box"
  log "installed sing-box to ${INSTALL_DIR}/sing-box"
}

backup_current_config() {
  local backup_file=""
  mkdir -p "${STATE_DIR}"
  if [[ -f "${CONFIG_PATH}" ]]; then
    backup_file="${STATE_DIR}/config.backup.$(date +%Y%m%d%H%M%S).json"
    cp "${CONFIG_PATH}" "${backup_file}"
    printf '%s\n' "${backup_file}" > "${STATE_DIR}/last_backup_path"
    log "backup created: ${backup_file}"
  fi
}

install_systemd_service() {
  need_cmd systemctl
  local unit_file="/etc/systemd/system/${SERVICE_NAME}.service"
  local sing_box_bin
  sing_box_bin="$(command -v sing-box || true)"
  [[ -n "${sing_box_bin}" ]] || die "sing-box binary not found in PATH after installation"

  cat > "${unit_file}" <<EOF
[Unit]
Description=sing-box service managed by fly
After=network.target
Wants=network-online.target

[Service]
Type=simple
ExecStart=${sing_box_bin} run -c ${CONFIG_PATH}
Environment=ENABLE_DEPRECATED_SPECIAL_OUTBOUNDS=${ENABLE_DEPRECATED_SPECIAL_OUTBOUNDS}
Restart=on-failure
RestartSec=2
LimitNOFILE=512000

[Install]
WantedBy=multi-user.target
EOF

  systemctl daemon-reload
  systemctl enable --now "${SERVICE_NAME}"
  systemctl restart "${SERVICE_NAME}"
  systemctl is-active --quiet "${SERVICE_NAME}" || die "service ${SERVICE_NAME} is not active"
}

healthcheck_proxy() {
  need_cmd curl
  local proxy_url="socks5h://127.0.0.1:${INBOUND_MIXED_PORT}"
  if curl -fsSL --max-time 15 --proxy "${proxy_url}" "${CHECK_URL}" >/dev/null 2>&1; then
    log "healthcheck passed via ${proxy_url}"
  else
    warn "healthcheck failed via ${proxy_url}; service may still be running"
  fi
}

cmd_apply() {
  local dry_run="false"
  while [[ $# -gt 0 ]]; do
    case "$1" in
      --dry-run) dry_run="true" ;;
      *) die "unknown flag for apply: $1" ;;
    esac
    shift
  done

  [[ -f "${GROUPS_FILE}" ]] || die "missing ${GROUPS_FILE}, run ./fly init first"
  [[ -f "${ROUTES_FILE}" ]] || die "missing ${ROUTES_FILE}, run ./fly init first"
  load_env

  need_cmd python3
  mkdir -p "${BUILD_DIR}" "${STATE_DIR}"

  local subscription_json="${BUILD_DIR}/subscription.json"
  local generated_config="${BUILD_DIR}/config.json"

  fetch_subscription_json "${subscription_json}"
  render_config "${subscription_json}" "${generated_config}"
  check_with_local_sing_box "${generated_config}"

  if is_true "${dry_run}"; then
    log "dry-run complete: generated ${generated_config}"
    exit 0
  fi

  require_root
  install_sing_box_if_needed

  install -d "$(dirname "${CONFIG_PATH}")"
  backup_current_config
  install -m 600 "${generated_config}" "${CONFIG_PATH}"
  log "applied config to ${CONFIG_PATH}"

  install_systemd_service
  healthcheck_proxy

  cp "${generated_config}" "${STATE_DIR}/last_applied_config.json"
  log "apply complete. Use ./fly status and ./fly logs for verification."
}

cmd_status() {
  load_env
  if command -v sing-box >/dev/null 2>&1; then
    sing-box version || true
  else
    warn "sing-box is not installed in PATH"
  fi

  if command -v systemctl >/dev/null 2>&1; then
    systemctl --no-pager --full status "${SERVICE_NAME}" || true
  else
    warn "systemctl not available on this host"
  fi

  if [[ -f "${STATE_DIR}/last_applied_config.json" ]]; then
    log "last applied config: ${STATE_DIR}/last_applied_config.json"
  fi
}

cmd_logs() {
  load_env
  local follow="false"
  local lines="100"

  while [[ $# -gt 0 ]]; do
    case "$1" in
      -f|--follow) follow="true" ;;
      -n|--lines)
        shift
        [[ $# -gt 0 ]] || die "missing value for --lines"
        lines="$1"
        ;;
      *)
        die "unknown logs flag: $1"
        ;;
    esac
    shift
  done

  need_cmd journalctl
  if is_true "${follow}"; then
    journalctl -u "${SERVICE_NAME}" -n "${lines}" -f
  else
    journalctl -u "${SERVICE_NAME}" -n "${lines}" --no-pager
  fi
}

cmd_rollback() {
  load_env
  require_root
  [[ -f "${STATE_DIR}/last_backup_path" ]] || die "no backup metadata found at ${STATE_DIR}/last_backup_path"
  local backup_file
  backup_file="$(cat "${STATE_DIR}/last_backup_path")"
  [[ -f "${backup_file}" ]] || die "backup file not found: ${backup_file}"

  install -m 600 "${backup_file}" "${CONFIG_PATH}"
  log "restored config from ${backup_file} -> ${CONFIG_PATH}"
  if command -v systemctl >/dev/null 2>&1; then
    systemctl restart "${SERVICE_NAME}"
    systemctl is-active --quiet "${SERVICE_NAME}" || die "service ${SERVICE_NAME} failed after rollback"
  fi
  log "rollback complete"
}

main() {
  local cmd="${1:-help}"
  shift || true

  case "${cmd}" in
    init) init_files "$@" ;;
    apply) cmd_apply "$@" ;;
    status) cmd_status "$@" ;;
    logs) cmd_logs "$@" ;;
    rollback) cmd_rollback "$@" ;;
    help|-h|--help) usage ;;
    version|-v|--version)
      printf '%s\n' "${FLY_VERSION}"
      ;;
    *)
      die "unknown command: ${cmd}. Run ./fly help"
      ;;
  esac
}

main "$@"
